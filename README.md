# hadoop3-cluster-docker

## æ–°å¢hive

å®¹å™¨å¯åŠ¨åï¼Œéœ€è¦æ£€æŸ¥hiveå’Œhadoopä½¿ç”¨çš„guavaåŒ…çš„ç‰ˆæœ¬æ˜¯å¦ä¸€è‡´ï¼Œ
ä¾‹å¦‚hadoopä½¿ç”¨çš„guavaçš„ç‰ˆæœ¬é«˜äºhiveä½¿ç”¨çš„guavaç‰ˆæœ¬ï¼Œé‚£ä¹ˆ `rm ${HIVE_HOME}/lib/guava-*.jar && cp ${HADOOP_HOME}/share/hadoop/common/lib/guava-*.jar ${HIVE_HOME}/lib/`.

hive å¯åŠ¨

é…ç½®:
```
# ----- hive-site.xml -----
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:mysql://mysql:3306/yhy</value>
    <description>
      JDBC connect string for a JDBC metastore.
      To use SSL to encrypt/authenticate the connection, provide database-specific SSL flag in the connection URL.
      For example, jdbc:postgresql://myhost/db?ssl=true for postgres database.
    </description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>com.mysql.cj.jdbc.Driver</value>
    <description>Driver class name for a JDBC metastore</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>yhy</value>
    <description>Username to use against metastore database</description>
  </property>
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>my-secret-pw</value>
    <description>password to use against metastore database</description>
  </property>


# åœ¨viä¸­æ›¿æ¢å˜é‡
:%s#${system:java.io.tmpdir}#/tmp/javaiotmp#
:%s#${system:user.name}#root#

----- hadoop core-site.xml -----
    <property>
        <name>hadoop.proxyuser.root.hosts</name>
        <value>*</value>
    </property>
    <property>
        <name>hadoop.proxyuser.root.groups</name>
        <value>*</value>
    </property>
```

åˆå§‹åŒ–å…ƒæ•°æ®åº“ï¼š`schematool -initSchema -dbType mysql`


é€šè¿‡hiveserver2
éœ€è¦å°†hive-site.xmlæ–‡ä»¶ä¸­çš„hive.server2.thrift.bind.hostå±æ€§é…ç½®ä¸ºhadoop01
```Bash
$ hiveserver2                     # å¯åŠ¨hiveserver2æœåŠ¡
$ hive --service hiveserver2 &    # åå°å¯åŠ¨hiveserver2æœåŠ¡

                                  # è¿æ¥hiveserver2
$ bin/beeline
beeline> !connect jdbc:hive2://hadoop01:10000
```

é€šè¿‡metastore
éœ€è¦å°†hive-site.xmlæ–‡ä»¶ä¸­çš„hive.metastore.uriså±æ€§é…ç½®ä¸ºthrift://hadoop01:9083, è¿™é‡Œè¦æ³¨æ„çš„æ˜¯ï¼Œç”±äºdockerçš„ç½‘ç»œåç§°ä¸­åŒ…å«ä¸‹åˆ’çº¿ï¼Œè¿œç¨‹è¿æ¥æ—¶ä¼šå‡ºç°URIè§£æå¤±è´¥ã€‚ä¸è¿‡æœ¬åœ°è¿æ¥é€šè¿‡/etc/hostsï¼ŒURIä¼šè§£ææˆåŠŸã€‚
```Bash
$ hive --service metastore &      # åå°å¯åŠ¨metastoreæœåŠ¡

$ bin/hive                        # è¿æ¥metastore

```

---
åˆ©ç”¨dockerå®¹å™¨æ¨¡æ‹Ÿhadoopé›†ç¾¤çš„éƒ¨ç½²ã€‚

ä½¿ç”¨æ­¥éª¤ï¼š

1. åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹æ”¾ç½®hadoop3çš„éƒ¨ç½²åŒ…ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ï¼Œå®˜æ–¹åŒ…åä¸º hadoop-x.x.x.tar.gz, å…¶ä¸­xxxä¸ºç‰ˆæœ¬å·
2. ä½¿ç”¨è„šæœ¬`build.sh`æ„å»ºé•œåƒï¼Œè„šæœ¬å†…éƒ¨çš„å‘½ä»¤`docker build -t hadoop-base --build-arg HADOOP_PACKAGE=hadoop-x.x.x .` æ„å»ºä¸€ä¸ªåä¸ºhadoop3çš„é•œåƒï¼Œæ­¤å¤„è®°å¾—å°†ç‰ˆæœ¬å·æ¢æˆè‡ªå·±æ‰€ç”¨çš„hadoopç‰ˆæœ¬å·ï¼›
3. ä¿®æ”¹etc-hadoopæ–‡ä»¶å¤¹ä¸‹çš„é…ç½®æ–‡ä»¶;
4. ä½¿ç”¨`docker-compose up` å¯åŠ¨hadoopå®¹å™¨é›†ç¾¤ï¼›

## å½“å‰é…ç½®
```Bash
# ----- core-site.xml -----
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://hadoop01:9820</value>
    </property>
    <property>
        <name>hadoop.http.staticuser.user</name>
        <value>root</value>
    </property>
</configuration>

# ----- hdfs-site.xml -----
<configuration>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>hdfs://hadoop02:9868</value>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.namenode.http-address</name>
        <value>hadoop01:9870</value>
    </property>
</configuration>

# ----- yarn-site.xml -----
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>hadoop01</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.scheduler.minimum-allocation-mb</name>
        <value>512</value>
    </property>
    <property>
        <name>yarn.scheduler.maximum-allocation-mb</name>
        <value>2048</value>
    </property>
    <property>
        <name>yarn.nodemanager.vmem-pmem-ratio</name>
        <value>4</value>
    </property>
</configuration>

# ----- mapred-site.xml -----
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
    <property>
        <name>yarn.app.mapreduce.am.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.map.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
    <property>
        <name>mapreduce.reduce.env</name>
        <value>HADOOP_MAPRED_HOME=${HADOOP_HOME}</value>
    </property>
</configuration>
# ----- hadoop-env.sh -----
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64

export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root


# ----- workers ----
hadoop01
hadoop02
hadoop03


```

å…³äºhadoopå®¹å™¨é›†ç¾¤çš„è§„åˆ’åœ¨æ–‡ä»¶docker-compose.ymlä¸­:
- hadoop01: NameNode, DataNode, NodeManager, ResourceManager, JobHistoryServer
- hadoop02: SecondaryNameNode, DataNode, NodeManager
- hadoop03: DataNode, NodeManager

æŒ‰ç…§å¦‚ä¸Šè§„åˆ’ï¼Œæ¥ä¸‹æ¥åº”è¯¥ï¼š
1. åœ¨hadoop01ä¸Šæ‰§è¡Œ`hdfs namenode -format`ï¼›
2. åœ¨hadoop01çš„${HADOOP_HOME}/sbin/ç›®å½•ä¸‹ï¼Œæ‰§è¡Œ`./start-dfs.sh`ï¼›
3. åœ¨hadoop01çš„${HADOOP_HOME}/sbin/ç›®å½•ä¸‹ï¼Œæ‰§è¡Œ`./start-yarn.sh`ï¼›
4. åœ¨hadoop01çš„${HADOOP_HOME}/sbin/ç›®å½•ä¸‹ï¼Œæ‰§è¡Œ`mapred --daemon start historyserver`ï¼›

æ¥ä¸‹æ¥å¼€å§‹æ„‰å¿«çš„hadoopä¹‹æ—…å§ï¼ğŸ˜

----- é›†ç¾¤å¯åŠ¨åœæ­¢ -----
```
start-dfs.sh     # å¯åŠ¨HDFSæ‰€æœ‰è¿›ç¨‹(NameNode, SecondaryNameNode, DataNode)
stop-dfs.sh      # åœæ­¢HDFSæ‰€æœ‰è¿›ç¨‹(NameNode, SecondaryNameNode, DataNode)

hdfs --daemon start namenode           # åªå¯åŠ¨NameNode
hdfs --daemon start secondarynamenode  # åªå¯åŠ¨SecondaryNameNode
hdfs --daemon start datanode           # åªå¯åŠ¨DataNode
# hdfs --daemon stop xxx               # åªåœæ­¢xxx

hdfs --workers --daemon start datanode   # å¯åŠ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„DataNode
hdfs --workers --daemon stop datanode    # åœæ­¢æ‰€æœ‰èŠ‚ç‚¹ä¸Šçš„DataNode

```
